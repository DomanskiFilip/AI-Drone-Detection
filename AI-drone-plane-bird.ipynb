{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FbIKo-g5mj5T"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle kagglehub opencv-python-headless scikit-learn pandas seaborn matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwLsRmgf1X23"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = userdata.get('KAGGLE_USERNAME')\n",
        "os.environ['KAGGLE_KEY'] = userdata.get('KAGGLE_KEY')\n",
        "\n",
        "# Create the config folder and file so the kaggle CLI works\n",
        "!mkdir -p ~/.kaggle\n",
        "!echo '{\"username\":\"'$KAGGLE_USERNAME'\",\"key\":\"'$KAGGLE_KEY'\"}' > ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print(\"Successfully configured Kaggle!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utils_cell"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy\n",
        "from sklearn.metrics import (\n",
        "    mean_absolute_error, mean_squared_error, r2_score,\n",
        "    precision_score, recall_score, f1_score, confusion_matrix,\n",
        "    classification_report\n",
        ")\n",
        "\n",
        "def load_and_preprocess_data(base_path, categories, img_size=(64, 64)):\n",
        "    data, labels = [], []\n",
        "    for folder_name, label in categories.items():\n",
        "        category_path = os.path.join(base_path, folder_name)\n",
        "        if not os.path.isdir(category_path):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(category_path):\n",
        "            # Skip system files and only keep images (skip thumb.db etc.)\n",
        "            if not img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                continue\n",
        "\n",
        "            img_path = os.path.join(category_path, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                # Resize to a standard size\n",
        "                img = cv2.resize(img, img_size)\n",
        "                # Normalize pixels to range [0, 1]\n",
        "                data.append(img.astype('float32') / 255.0)\n",
        "                labels.append(label)\n",
        "\n",
        "    return numpy.array(data), numpy.array(labels)\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, class_names=None):\n",
        "    predictions = model.predict(X_test)\n",
        "    accuracy = (numpy.sum(predictions == y_test) / len(y_test)) * 100\n",
        "\n",
        "    # Precision: correctly predicted / the total predicted\n",
        "    # High precision means fewer false positives.\n",
        "    precision = precision_score(y_test, predictions, average='weighted', zero_division=0)\n",
        "    # Recall:  correctly predicted / all observations in actual class\n",
        "    # High recall means fewer false negatives.\n",
        "    recall = recall_score(y_test, predictions, average='weighted', zero_division=0)\n",
        "    # F1-Score: The weighted average of Precision and Recall. It tries to find the balance between precision and recall\n",
        "    # A high F1-score indicates good performance for both precision and recall\n",
        "    f1 = f1_score(y_test, predictions, average='weighted', zero_division=0)\n",
        "    # Confusion Matrix: A table that shows the counts of true positives, true negatives, false positives, and false negatives\n",
        "    cm = confusion_matrix(y_test, predictions)\n",
        "    # Mean Absolute Error (MAE): The average of the absolute differences between predictions and actual values\n",
        "    # It gives an idea of the average magnitude of errors.\n",
        "    mae = mean_absolute_error(y_test, predictions)\n",
        "    # Root Mean Squared Error (RMSE): The square root of the average of the squared differences between predictions and actual values\n",
        "    # average distance from correct predicton\n",
        "    rmse = numpy.sqrt(mean_squared_error(y_test, predictions))\n",
        "    # R-squared (R2 Score): Represents the proportion of the variance in the dependent variable that is predictable\n",
        "    # 1 means model understands the class perfectly 0 means model is no better than random guessing - means model does not capture any of the variance in the data\n",
        "    r2 = r2_score(y_test, predictions)\n",
        "\n",
        "    results = {\n",
        "        \"model\":     model.name,\n",
        "        \"accuracy\":  round(accuracy, 4),\n",
        "        \"precision\": round(precision, 4),\n",
        "        \"recall\":    round(recall, 4),\n",
        "        \"f1\":        round(f1, 4),\n",
        "        \"mae\":       round(mae, 4),\n",
        "        \"rmse\":      round(rmse, 4),\n",
        "        \"r2\":        round(r2, 4),\n",
        "        \"confusion_matrix\": cm.tolist()\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Results for: {model.name}\")\n",
        "    print(f\"  Accuracy:  {accuracy:.2f}%\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "    print(f\"  Recall:    {recall:.4f}\")\n",
        "    print(f\"  F1-Score:  {f1:.4f}\")\n",
        "    print(f\"  MAE:       {mae:.4f}\")\n",
        "    print(f\"  RMSE:      {rmse:.4f}\")\n",
        "    print(f\"  R\\u00b2:        {r2:.4f}\")\n",
        "    if class_names:\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(y_test, predictions, target_names=class_names))\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def clean_nan_values(data_input):\n",
        "    nan_representations = ['--', 'na', 'n/a', 'nan', 'none', '']\n",
        "\n",
        "    data_array = numpy.asarray(data_input, dtype=object)\n",
        "    cleaned_array = numpy.copy(data_array)\n",
        "\n",
        "    # Iterate through each element of the array\n",
        "    it = numpy.nditer(data_array, flags=['multi_index', 'refs_ok'])\n",
        "    for x in it:\n",
        "        idx = it.multi_index\n",
        "        value = x.item()  # Get the actual value from array\n",
        "\n",
        "        if isinstance(value, str):\n",
        "            # If the value is a string, check if its lowercase version matches any NaN representation\n",
        "            if value.lower() in nan_representations:\n",
        "                cleaned_array[idx] = numpy.nan\n",
        "        elif value is None:\n",
        "            # Explicitly treat Python's None as a NaN\n",
        "            cleaned_array[idx] = numpy.nan\n",
        "\n",
        "    # Attempt to convert the cleaned array to a floating-point numeric type\n",
        "    try:\n",
        "        temp_numeric_array = cleaned_array.astype(float)\n",
        "        cleaned_array = temp_numeric_array\n",
        "    except ValueError:\n",
        "        print(\"Warning: Some values could not be converted to numeric type after NaN cleaning. \"\n",
        "              \"The array will remain of object dtype to preserve data integrity.\")\n",
        "\n",
        "    return cleaned_array\n",
        "\n",
        "print(\"utils.py loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "models_cell"
      },
      "outputs": [],
      "source": [
        "# Algorythm 1 Euclidean Distance: looking at nearest neighbour and predicting as that class\n",
        "class EuclideanDistance:\n",
        "    def __init__(self):\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "        self.name = \"Euclidean Distance\"\n",
        "\n",
        "    def train(self, X_train, y_train):\n",
        "        print(f\"\\nTraining {self.name}...\")\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        print(f\"Memorized {len(X_train)} training examples\")\n",
        "\n",
        "    def predict_single(self, x):\n",
        "        # Calculate Euclidean distance to all training samples\n",
        "        # Distance formula: sqrt(sum((x - train_sample)^2))\n",
        "        distances = numpy.sqrt(numpy.sum((self.X_train - x)**2, axis=1))\n",
        "\n",
        "        # Find the index of the smallest distance\n",
        "        closest_index = numpy.argmin(distances)\n",
        "\n",
        "        # Return the label of the closest training sample\n",
        "        return self.y_train[closest_index]\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        predictions = []\n",
        "        for x in X_test:\n",
        "            predictions.append(self.predict_single(x))\n",
        "        return numpy.array(predictions)\n",
        "\n",
        "\n",
        "# Algorythm 2 K Nearest Neighbours: looking at k nearest neighbours and predicting as most popular class among them\n",
        "class KNearestNeighbors:\n",
        "    def __init__(self, k=3):\n",
        "        # k: Number of neighbors to vote (default 3)\n",
        "        self.k = k\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "        self.name = f\"K-Nearest Neighbors (k={k})\"\n",
        "\n",
        "    def train(self, X_train, y_train):\n",
        "        print(f\"\\nTraining {self.name}...\")\n",
        "        self.X_train = numpy.array(X_train)\n",
        "        self.y_train = numpy.array(y_train)\n",
        "        print(f\"Memorized {len(X_train)} training examples\")\n",
        "\n",
        "    def predict_single(self, x):\n",
        "        # Calculate distances\n",
        "        distances = numpy.sqrt(numpy.sum((self.X_train - x)**2, axis=1))\n",
        "\n",
        "        # Get indices of K nearest neighbors\n",
        "        # numpy.argpartition finds K smallest values efficiently\n",
        "        k_indices = numpy.argpartition(distances, self.k)[:self.k].astype(int)\n",
        "\n",
        "        # Get labels of K nearest neighbors\n",
        "        k_labels = self.y_train[k_indices]\n",
        "\n",
        "        # Count votes for each class\n",
        "        # Find which class got the most votes\n",
        "        unique_labels, counts = numpy.unique(k_labels, return_counts=True)\n",
        "        winner = unique_labels[numpy.argmax(counts)]\n",
        "\n",
        "        return winner\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        predictions = []\n",
        "        for x in X_test:\n",
        "            predictions.append(self.predict_single(x))\n",
        "        return numpy.array(predictions)\n",
        "\n",
        "\n",
        "# Algorythm 3 Multi Layer Perceptron: A calssical neural network that trains x ammount of perceprtons over y epochs then predicts based on activated trained features\n",
        "class MultiLayerPerceptron:\n",
        "    def __init__(self, hidden_neurons=150, epochs=50, learning_rate=0.1, random_seed=42):\n",
        "        self.hidden_neurons = hidden_neurons\n",
        "        self.epochs = epochs\n",
        "        self.learning_rate = learning_rate\n",
        "        self.random_seed = random_seed\n",
        "        self.name = f\"Multi-Layer Perceptron ({hidden_neurons} neurons, {epochs} epochs)\"\n",
        "\n",
        "        # These will be set during training\n",
        "        self.weights_input_hidden = None\n",
        "        self.bias_hidden = None\n",
        "        self.weights_hidden_output = None\n",
        "        self.bias_output = None\n",
        "        self.feature_mean = None\n",
        "        self.feature_std = None\n",
        "        self.n_classes = None\n",
        "        self.input_size = None\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        # Sigmoid activation function: squashes values to range (0, 1)\n",
        "        # Formula: 1 / (1 + e^(-x))\n",
        "        return 1.0 / (1.0 + numpy.exp(-numpy.clip(x, -500, 500)))\n",
        "\n",
        "    def sigmoid_derivative(self, activated_value):\n",
        "        # Derivative of sigmoid - used in backpropagation\n",
        "        # Formula: sigmoid(x) * (1 - sigmoid(x))\n",
        "        return activated_value * (1.0 - activated_value)\n",
        "\n",
        "    def normalize_features(self, X):\n",
        "        # Normalize features to have mean=0, std=1\n",
        "        if self.feature_mean is None:\n",
        "            # First time - calculate mean and std from training data\n",
        "            self.feature_mean = numpy.mean(X, axis=0)\n",
        "            self.feature_std = numpy.std(X, axis=0)\n",
        "            # Prevent division by zero\n",
        "            self.feature_std[self.feature_std < 1e-9] = 1.0\n",
        "\n",
        "        # Apply normalization\n",
        "        return (X - self.feature_mean) / self.feature_std\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        # Initialize weights randomly\n",
        "        numpy.random.seed(self.random_seed)\n",
        "        weight_range = 0.1\n",
        "\n",
        "        # Weights from input to hidden layer\n",
        "        self.weights_input_hidden = (numpy.random.rand(self.hidden_neurons, self.input_size) * 2 - 1) * weight_range\n",
        "        self.bias_hidden = (numpy.random.rand(self.hidden_neurons) * 2 - 1) * weight_range\n",
        "\n",
        "        # Weights from hidden to output layer\n",
        "        self.weights_hidden_output = (numpy.random.rand(self.n_classes, self.hidden_neurons) * 2 - 1) * weight_range\n",
        "        self.bias_output = (numpy.random.rand(self.n_classes) * 2 - 1) * weight_range\n",
        "\n",
        "    def forward_pass(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass: push data through the network\n",
        "\n",
        "        Steps:\n",
        "        1. Input -> Hidden layer (with sigmoid activation)\n",
        "        2. Hidden -> Output layer (with sigmoid activation)\n",
        "        \"\"\"\n",
        "        # Input to hidden layer\n",
        "        hidden_sum = numpy.dot(self.weights_input_hidden, x) + self.bias_hidden\n",
        "        hidden_activation = self.sigmoid(hidden_sum)\n",
        "\n",
        "        # Hidden to output layer\n",
        "        output_sum = numpy.dot(self.weights_hidden_output, hidden_activation) + self.bias_output\n",
        "        output_activation = self.sigmoid(output_sum)\n",
        "\n",
        "        return hidden_activation, output_activation\n",
        "\n",
        "    def train(self, X_train, y_train):\n",
        "        \"\"\"\n",
        "        Train the neural network using backpropagation\n",
        "\n",
        "        Backpropagation:\n",
        "        1. Make a prediction (forward pass)\n",
        "        2. Calculate how wrong we were (error)\n",
        "        3. Adjust weights to reduce error (backward pass)\n",
        "        4. Repeat many times\n",
        "        \"\"\"\n",
        "        print(f\"\\nTraining {self.name}...\")\n",
        "        print(\"This may take a minute...\")\n",
        "\n",
        "        # Get dimensions\n",
        "        n_samples, self.input_size = X_train.shape\n",
        "        self.n_classes = len(numpy.unique(y_train))\n",
        "\n",
        "        # Normalize features\n",
        "        X_normalized = self.normalize_features(X_train)\n",
        "\n",
        "        # Initialize weights\n",
        "        self.initialize_weights()\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(self.epochs):\n",
        "            correct = 0\n",
        "\n",
        "            # Go through each training example\n",
        "            for i in range(n_samples):\n",
        "                x = X_normalized[i]\n",
        "                target_class = y_train[i]\n",
        "\n",
        "                # FORWARD PASS: Make a prediction\n",
        "                hidden, output = self.forward_pass(x)\n",
        "\n",
        "                # Create target vector (one-hot encoding)\n",
        "                # Example: if target_class=1 and n_classes=3, target=[0, 1, 0]\n",
        "                target = numpy.zeros(self.n_classes)\n",
        "                target[target_class] = 1.0\n",
        "\n",
        "                # CALCULATE ERROR\n",
        "                # Output layer error\n",
        "                output_error = target - output\n",
        "                output_delta = output_error * self.sigmoid_derivative(output)\n",
        "\n",
        "                # Hidden layer error (backpropagate)\n",
        "                hidden_error = numpy.dot(self.weights_hidden_output.T, output_delta)\n",
        "                hidden_delta = hidden_error * self.sigmoid_derivative(hidden)\n",
        "\n",
        "                # UPDATE WEIGHTS (gradient descent)\n",
        "                # Hidden to output weights\n",
        "                self.weights_hidden_output += self.learning_rate * numpy.outer(output_delta, hidden)\n",
        "                self.bias_output += self.learning_rate * output_delta\n",
        "\n",
        "                # Input to hidden weights\n",
        "                self.weights_input_hidden += self.learning_rate * numpy.outer(hidden_delta, x)\n",
        "                self.bias_hidden += self.learning_rate * hidden_delta\n",
        "\n",
        "                # Track accuracy\n",
        "                if numpy.argmax(output) == target_class:\n",
        "                    correct += 1\n",
        "\n",
        "            # Print progress every 10 epochs\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                accuracy = (correct / n_samples) * 100\n",
        "                print(f\"  Epoch {epoch + 1}/{self.epochs} - Training accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "        print(\"Training complete!\")\n",
        "\n",
        "    def predict_single(self, x):\n",
        "        _, output = self.forward_pass(x)\n",
        "        return numpy.argmax(output)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        # Normalize test data using training statistics\n",
        "        X_normalized = (X_test - self.feature_mean) / self.feature_std\n",
        "\n",
        "        predictions = []\n",
        "        for x in X_normalized:\n",
        "            predictions.append(self.predict_single(x))\n",
        "\n",
        "        return numpy.array(predictions)\n",
        "\n",
        "print(\"models.py loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_tracker_cell"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "RESULTS_FILE = \"run_history.csv\"\n",
        "\n",
        "def save_run(results: dict, notes: str = \"\"):\n",
        "    # Append a single model evaluation result to the CSV history\n",
        "    # Flatten the confusion matrix to a JSON string so it fits in one cell\n",
        "    row = {key: value for key, value in results.items() if key != \"confusion_matrix\"}\n",
        "    row[\"confusion_matrix\"] = json.dumps(results.get(\"confusion_matrix\", []))\n",
        "    row[\"timestamp\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    row[\"notes\"] = notes\n",
        "\n",
        "    dataFrame_new = pandas.DataFrame([row])\n",
        "\n",
        "    if os.path.exists(RESULTS_FILE):\n",
        "        dataFrame_existing = pandas.read_csv(RESULTS_FILE)\n",
        "        dataFrame_combined = pandas.concat([dataFrame_existing, dataFrame_new], ignore_index=True)\n",
        "    else:\n",
        "        dataFrame_combined = dataFrame_new\n",
        "\n",
        "    dataFrame_combined.to_csv(RESULTS_FILE, index=False)\n",
        "    print(f\"Run saved to {RESULTS_FILE}\")\n",
        "\n",
        "def load_runs() -> pandas.DataFrame:\n",
        "    # Load all historical runs into a DataFrame\n",
        "    if not os.path.exists(RESULTS_FILE):\n",
        "        print(\"No run history found.\")\n",
        "        return pandas.DataFrame()\n",
        "    return pandas.read_csv(RESULTS_FILE)\n",
        "\n",
        "print(\"run_tracker.py loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "visualise_cell"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "import seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import json\n",
        "import numpy\n",
        "\n",
        "def plot_metrics_over_runs(df: pandas.DataFrame):\n",
        "    # Line plot of key metrics across runs, grouped by model\n",
        "    metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\", \"rmse\", \"r2\"]\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
        "    fig.suptitle(\"Model Metrics Across Runs\", fontsize=16, fontweight=\"bold\")\n",
        "\n",
        "    for ax, metric in zip(axes.flatten(), metrics):\n",
        "        seaborn.lineplot(\n",
        "            data=df,\n",
        "            x=df.index,\n",
        "            y=metric,\n",
        "            hue=\"model\",\n",
        "            marker=\"o\",\n",
        "            ax=ax\n",
        "        )\n",
        "        ax.set_title(metric.upper())\n",
        "        ax.set_xlabel(\"Run #\")\n",
        "        ax.set_ylabel(metric)\n",
        "        ax.legend(fontsize=7)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"metrics_over_runs.png\", dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_model_comparison(df: pandas.DataFrame):\n",
        "    # Bar chart comparing latest run metrics per model\n",
        "    # Take the most recent run per model\n",
        "    latest = df.sort_values(\"timestamp\").groupby(\"model\").last().reset_index()\n",
        "\n",
        "    # Convert precision, recall, and f1 to percentage for better comparison on the graph\n",
        "    latest[\"precision\"] = latest[\"precision\"] * 100\n",
        "    latest[\"recall\"] = latest[\"recall\"] * 100\n",
        "    latest[\"f1\"] = latest[\"f1\"] * 100\n",
        "\n",
        "    melted = latest.melt(\n",
        "        id_vars=\"model\",\n",
        "        value_vars=[\"accuracy\", \"precision\", \"recall\", \"f1\"],\n",
        "        var_name=\"Metric\",\n",
        "        value_name=\"Score\"\n",
        "    )\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    seaborn.barplot(data=melted, x=\"Metric\", y=\"Score\", hue=\"model\", palette=\"Set2\")\n",
        "    plt.title(\"Latest Run: Model Comparison\")\n",
        "    plt.ylim(0, 105)  # Set y-limit to accommodate percentage values\n",
        "    plt.legend(title=\"Model\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"model_comparison.png\", dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_confusion_matrices(df: pandas.DataFrame, class_names: list):\n",
        "    # Plot confusion matrices for the most recent run of each model\n",
        "    latest = df.sort_values(\"timestamp\").groupby(\"model\").last().reset_index()\n",
        "    n_models = len(latest)\n",
        "\n",
        "    fig, axes = plt.subplots(1, n_models, figsize=(6 * n_models, 5))\n",
        "    if n_models == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for ax, (_, row) in zip(axes, latest.iterrows()):\n",
        "        cm = numpy.array(json.loads(row[\"confusion_matrix\"]))\n",
        "        seaborn.heatmap(\n",
        "            cm,\n",
        "            annot=True,\n",
        "            fmt=\"d\",\n",
        "            cmap=\"Blues\",\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names,\n",
        "            ax=ax\n",
        "        )\n",
        "        ax.set_title(f\"{row['model']}\\nConfusion Matrix\")\n",
        "        ax.set_xlabel(\"Predicted\")\n",
        "        ax.set_ylabel(\"Actual\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"confusion_matrices.png\", dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_error_metrics(df: pandas.DataFrame):\n",
        "    # Box plot of error metrics (MAE, RMSE) distribution per model across all runs\n",
        "    melted = df.melt(\n",
        "        id_vars=\"model\",\n",
        "        value_vars=[\"mae\", \"rmse\"],\n",
        "        var_name=\"Error Metric\",\n",
        "        value_name=\"Value\"\n",
        "    )\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    seaborn.boxplot(data=melted, x=\"model\", y=\"Value\", hue=\"Error Metric\", palette=\"Set1\")\n",
        "    plt.title(\"Error Metric Distribution Across Runs\")\n",
        "    plt.xticks(rotation=15)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"error_metrics.png\", dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "print(\"visualise.py loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "main_data_cell"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "import numpy\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Download the dataset\n",
        "path = kagglehub.dataset_download(\"maryamlsgumel/drone-detection-dataset\")\n",
        "base_path = f\"{path}/BirdVsDroneVsAirplane\"\n",
        "\n",
        "categories = {'Birds': 0, 'Drones': 1, 'Aeroplanes': 2}\n",
        "class_names = list(categories.keys())\n",
        "\n",
        "# Load Data\n",
        "print(\"Loading data...\")\n",
        "data, labels = load_and_preprocess_data(base_path, categories)\n",
        "\n",
        "# Clean NaN values\n",
        "print(\"Cleaning NaN values...\")\n",
        "data = clean_nan_values(data)\n",
        "labels = clean_nan_values(labels).astype(int)\n",
        "\n",
        "# Flatten\n",
        "n_samples = data.shape[0]\n",
        "features = data.reshape(n_samples, -1)\n",
        "\n",
        "# Show class distribution\n",
        "unique_labels, counts = numpy.unique(labels, return_counts=True)\n",
        "label_map = {0: \"Birds\", 1: \"Drones\", 2: \"Aeroplanes\"}\n",
        "print(f\"\\nClass distribution:\")\n",
        "for label, count in zip(unique_labels, counts):\n",
        "    print(f\"  {label_map[label]}: {count} samples ({count/len(labels)*100:.1f}%)\")\n",
        "\n",
        "# Train / Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features, labels, test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "print(f\"\\nTrain/Test Split:\")\n",
        "print(f\"  Training samples:  {len(X_train)} ({len(X_train)/len(features)*100:.1f}%)\")\n",
        "print(f\"  Testing samples:   {len(X_test)} ({len(X_test)/len(features)*100:.1f}%)\")\n",
        "print(f\"{'='*60}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hikBQx1ycYys"
      },
      "outputs": [],
      "source": [
        "# Visualize a random sample from the dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Pick a random index\n",
        "idx = random.randint(0, len(data) - 1)\n",
        "\n",
        "# Display the image and its label\n",
        "plt.imshow(data[idx])\n",
        "plt.title(f\"Label: {labels[idx]} (0:Bird, 1:Drone, 2:Plane)\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "main_train_cell"
      },
      "outputs": [],
      "source": [
        "# Train all models, evaluate, and save runs\n",
        "models = [\n",
        "    EuclideanDistance(),\n",
        "    KNearestNeighbors(k=5),\n",
        "    MultiLayerPerceptron(hidden_neurons=150, epochs=50)\n",
        "]\n",
        "\n",
        "for model in models:\n",
        "    print(f\"\\nTraining {model.name}...\")\n",
        "    model.train(X_train, y_train)\n",
        "    results = evaluate_model(model, X_test, y_test, class_names)\n",
        "    save_run(results, notes=\"baseline run\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "visualise_run_cell"
      },
      "outputs": [],
      "source": [
        "# Generate all charts from run history\n",
        "dataFrame = load_runs()\n",
        "\n",
        "if dataFrame.empty:\n",
        "    print(\"No run history found â€” train some models first!\")\n",
        "else:\n",
        "    print(f\"Loaded {len(dataFrame)} run(s) from history.\\n\")\n",
        "    plot_metrics_over_runs(dataFrame)\n",
        "    plot_model_comparison(dataFrame)\n",
        "    plot_confusion_matrices(dataFrame, class_names)\n",
        "    plot_error_metrics(dataFrame)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
